"""Basic RAG usage example.

–ü—Ä–æ—Å—Ç–æ–π –ø—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è RAG –º–æ–¥—É–ª—è –¥–ª—è –Ω–æ–≤–∏—á–∫–æ–≤.
–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –±–∞–∑–æ–≤—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏: –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ –ø–æ–∏—Å–∫.
"""

import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º RAG –º–æ–¥—É–ª—å –≤ PYTHONPATH
sys.path.insert(0, str(Path(__file__).parent.parent))

from rag_module.services import RAGManager
from rag_module.utils import format_search_results, format_stats


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–∏–º–µ—Ä–∞."""
    print("‚ú® RAG Basic Example - –ü—Ä–æ—Å—Ç–æ–π –ø—Ä–∏–º–µ—Ä\n")
    
    # –®–∞–≥ 1: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG Manager
    print("üöÄ –®–∞–≥ 1: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG Manager...")
    manager = RAGManager(
        persist_directory=Path("./rag_data"),  # –ì–¥–µ —Ö—Ä–∞–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ
        collection_name="basic_example",  # –ò–º—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏
    )
    print("‚úÖ RAG Manager –≥–æ—Ç–æ–≤!\n")
    
    # –®–∞–≥ 2: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    print("üìÑ –®–∞–≥ 2: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞...")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —Ç–µ—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã
    sample_dir = Path(__file__).parent / "sample_documents"
    
    if sample_dir.exists():
        # –ò—â–µ–º PDF —Ñ–∞–π–ª—ã
        pdf_files = list(sample_dir.glob("*.pdf"))
        if pdf_files:
            doc_path = pdf_files[0]
            print(f"  –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∞–π–ª: {doc_path.name}")
            
            document = manager.add_document(
                file_path=doc_path,
                doc_id="sample_doc_001",
                metadata={
                    "source": "example",
                    "type": "tutorial",
                },
            )
            
            print(f"  ‚úÖ –î–æ–∫—É–º–µ–Ω—Ç –¥–æ–±–∞–≤–ª–µ–Ω: {document.filename}")
            print(f"  üìÇ –°–æ–∑–¥–∞–Ω–æ —á–∞–Ω–∫–æ–≤: {document.chunk_count}\n")
        else:
            print("  ‚ö†Ô∏è PDF —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç...\n")
            create_test_document(manager)
    else:
        print("  ‚ö†Ô∏è –ü–∞–ø–∫–∞ sample_documents –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç...\n")
        create_test_document(manager)
    
    # –®–∞–≥ 3: –ü–æ–∏—Å–∫
    print("üîç –®–∞–≥ 3: –ü–æ–∏—Å–∫ –ø–æ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π...")
    
    queries = [
        "–ß—Ç–æ —Ç–∞–∫–æ–µ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç?",
        "What is machine learning?",
        "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç RAG?",
    ]
    
    for query in queries:
        print(f"\nüí¨ –ó–∞–ø—Ä–æ—Å: '{query}'")
        
        results = manager.search(
            query=query,
            top_k=3,  # –í–µ—Ä–Ω—É—Ç—å —Ç–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        )
        
        if results:
            print(f"  ‚úÖ –ù–∞–π–¥–µ–Ω–æ: {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            
            for idx, result in enumerate(results, 1):
                print(f"\n  [{idx}] üìä Relevance: {result.similarity_score:.1%}")
                print(f"      üìÑ Source: {result.source_doc}")
                print(f"      üìù Text: {result.chunk.text[:150]}...")
        else:
            print("  ‚ùå –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    
    # –®–∞–≥ 4: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\n\nüìä –®–∞–≥ 4: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã")
    stats = manager.get_stats()
    print(format_stats(stats, format="plain"))
    
    print("\n\n‚ú® –ü—Ä–∏–º–µ—Ä –∑–∞–≤–µ—Ä—à–µ–Ω!")
    print("üí° Tip: –ò–∑–º–µ–Ω–∏—Ç–µ –∑–∞–ø—Ä–æ—Å—ã –∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å–Ω–æ–≤–∞!")


def create_test_document(manager: RAGManager):
    """–°–æ–∑–¥–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞."""
    from rag_module.models import Document, Chunk
    from datetime import datetime
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç —Å —á–∞–Ω–∫–∞–º–∏
    test_texts = [
        "–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç (AI) - —ç—Ç–æ –æ–±–ª–∞—Å—Ç—å –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω—ã—Ö –Ω–∞—É–∫, –∫–æ—Ç–æ—Ä–∞—è –∑–∞–Ω–∏–º–∞–µ—Ç—Å—è —Å–æ–∑–¥–∞–Ω–∏–µ–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã—Ö –º–∞—à–∏–Ω.",
        "Machine learning is a subset of AI that enables systems to learn and improve from experience without being explicitly programmed.",
        "RAG (Retrieval-Augmented Generation) - —ç—Ç–æ –º–µ—Ç–æ–¥ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ–∏—Å–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –æ—Ç–≤–µ—Ç–æ–≤.",
        "Vector embeddings are numerical representations of text that capture semantic meaning.",
        "–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ–∑–≤–æ–ª—è–µ—Ç –Ω–∞—Ö–æ–¥–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ —Å–º—ã—Å–ª—É, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º.",
    ]
    
    chunks = []
    for idx, text in enumerate(test_texts):
        chunk = Chunk(
            id=f"test_chunk_{idx}",
            doc_id="test_document",
            text=text,
            position=idx,
            metadata={"source": "generated"},
        )
        chunks.append(chunk)
    
    # –î–æ–±–∞–≤–ª—è–µ–º —á–∞–Ω–∫–∏ –Ω–∞–ø—Ä—è–º—É—é
    manager.retriever.add_chunks(chunks)
    
    print(f"  ‚úÖ –°–æ–∑–¥–∞–Ω —Ç–µ—Å—Ç–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç —Å {len(chunks)} —á–∞–Ω–∫–∞–º–∏\n")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n‚è∏Ô∏è –ü—Ä–∏–º–µ—Ä –ø—Ä–µ—Ä–≤–∞–Ω")
    except Exception as e:
        print(f"\n\n‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()

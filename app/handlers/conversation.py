"""–ö–æ–Ω–≤–µ—Ä—Å–∞—Ü–∏—è –º–æ–¥–µ —Ö–∞–Ω–¥–ª–µ—Ä—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.

POLNAYA PODDERZHKA:
- Word: .docx, .doc
- Excel: .xlsx, .xls  
- PDF
- Text: .txt
- Images: .jpg, .png (OCR)

UPDATED 2025-12-28 20:57:
- REMOVED format restrictions
- Support ALL formats via openpyxl + pandas
- Graceful error handling only on actual failures

UPDATED 2025-12-25 14:48:
- Added user_id parameter to analyze_document calls
- All logging now includes user context

Fixes 2025-12-25 11:27:
- –ê–†–•–ò–¢–ï–ö–¢–£–†–ù–ê–Ø –û–ü–¢–ò–ú–∏–∑–∞—Ü–∏—è: –≠–ö–°–ü–õ–ò–¶–ò–¢–ù–´–ï state filters –≤ –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä–∞—Ö
- –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Å—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç –¢–û–õ–¨–ö–û –∫–æ–≥–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –í ConversationStates.ready
- –í –¥—Ä—É–≥–∏—Ö —Ä–µ–∂–∏–º–∞—Ö (–¥–æ–º–∞—à–∫–∞, –ø—Ä–æ–º–ø—Ç—ã) –¥–æ–∫—É–º–µ–Ω—Ç—ã –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞–º–∏
- –ù–ò–ö–ê–ö–û–ì–û –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞ –º–µ–∂–¥—É —Ä–µ–∂–∏–º–∞–º–∏ –≤–æ–≤–ª–µ

Handles document analysis and user prompts for interactive conversation.
"""

import logging
import uuid
from pathlib import Path

from aiogram import Router, F
from aiogram.filters import Command
from aiogram.types import Message, Document, File, CallbackQuery, InlineKeyboardButton, InlineKeyboardMarkup
from aiogram.fsm.context import FSMContext
from aiogram.utils.keyboard import InlineKeyboardBuilder

from app.config import get_settings
from app.states.conversation import ConversationStates
from app.services.file_processing.converter import FileConverter
from app.services.llm.llm_factory import LLMFactory
from app.services.prompts.prompt_manager import PromptManager
from app.utils.text_splitter import TextSplitter
from app.utils.cleanup import CleanupManager

logger = logging.getLogger(__name__)

router = Router()
config = get_settings()
prompt_manager = PromptManager()
llm_factory = LLMFactory(
    primary_provider=config.LLM_PROVIDER,
    openai_api_key=config.OPENAI_API_KEY or None,
    openai_model=config.OPENAI_MODEL,
    replicate_api_token=config.REPLICATE_API_TOKEN or None,
    replicate_model=config.REPLICATE_MODEL,
)


def _get_prompts_keyboard(user_id: int) -> InlineKeyboardMarkup:
    """–ü–æ–ª—É—á–∏—Ç—å –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Å ONLY –¥–æ–∫—É–º–µ–Ω—Ç–Ω—ã–º–∏ –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–º–ø—Ç–∞–º–∏ - 2 –∫–Ω–æ–ø–∫–∏ –≤ —Å—Ç—Ä–æ–∫–µ.
    
    –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ–º get_prompt_by_category() –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è
    –¢–û–õ–¨–ö–û –ø—Ä–æ–º–ø—Ç–æ–≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ "document_analysis", –∞ –ù–ï –≤—Å–µ—Ö –ø—Ä–æ–º–ø—Ç–æ–≤.
    """
    # –õ–æ–∞–¥–∏–º –ø—Ä–æ–º–ø—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    prompt_manager.load_user_prompts(user_id)
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü–æ–ª—É—á–∞–µ–º –¢–û–õ–¨–ö–û –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤
    prompts = prompt_manager.get_prompt_by_category(user_id, "document_analysis")
    
    logger.debug(f"User {user_id}: Loading {len(prompts)} DOCUMENT ANALYSIS prompts")
    
    builder = InlineKeyboardBuilder()
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫–∏ —Ç–æ–ª—å–∫–æ –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤
    for name in sorted(prompts.keys()):
        prompt = prompts[name]
        button_text = f"{prompt.description[:40]}"
        builder.button(
            text=button_text,
            callback_data=f"analyze_select_prompt_{name}"
        )
    
    # –ö–Ω–æ–ø–∫–∞ –æ—Ç–º–µ–Ω—ã
    builder.button(text="¬´ –û—Ç–º–µ–Ω–∞", callback_data="analyze_cancel")
    builder.adjust(2)  # 2 –∫–Ω–æ–ø–∫–∏ –≤ —Ä—è–¥—É
    
    return builder.as_markup()


@router.message(Command("analyze"))
async def cmd_analyze(message: Message, state: FSMContext) -> None:
    """–ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∂–∏–º –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ - —Ç–µ–ø–µ—Ä—å —Å –≤—ã–±–æ—Ä–æ–º –ø—Ä–æ–º–ø—Ç–∞."""
    logger.info(f"User {message.from_user.id} activated /analyze")
    await start_analyze_mode(message=message, state=state)


async def start_analyze_mode(callback: CallbackQuery = None, message: Message = None, state: FSMContext = None) -> None:
    """–ù–∞—á–∞—Ç—å –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.
    
    NEW: –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –≤—ã–±–æ—Ä –ø—Ä–æ–º–ø—Ç–∞ –í –ü–ï–†–í–´–•, —Ç–æ –≤–∞–ø—Ä–æ—Å–∏—é –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞.
    –¢–û–õ–¨–ö–û –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤!
    """
    if state is None:
        logger.error("state is None in start_analyze_mode")
        return
    
    user_id = message.from_user.id if message else callback.from_user.id if callback else None
    
    if not user_id:
        logger.error("Cannot determine user_id")
        return
    
    # Load user prompts
    prompt_manager.load_user_prompts(user_id)
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü–æ–ª—É—á–∞–µ–º –¢–û–õ–¨–ö–û –¥–æ–∫—É–º–µ–Ω—Ç–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã
    prompts = prompt_manager.get_prompt_by_category(user_id, "document_analysis")
    
    await state.set_state(ConversationStates.selecting_prompt)
    
    text = (
        "üìì *–ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤*\n\n"
        "–®–∞–≥ 1‚òÖ1‚òÖ1 –∏–∑ 2: *–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –∞–Ω–∞–ª–∏–∑–∞*\n\n"
        f"üìÑ *–î–æ—Å—Ç—É–ø–Ω–æ: {len(prompts)} –ø—Ä–æ–º–ø—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞*\n\n"
        "üîô *–ü–û–î–î–ï–†–ñ–ò–í–ê–ï–ú–´–ï –§–û–†–ú–ê–¢–´:*\n"
        "‚Ä¢ Word: .docx, **.doc** (–°–¢–ê–†–´–ô)\n"
        "‚Ä¢ Excel: .xlsx, **.xls** (–°–¢–ê–†–´–ô)\n"
        "‚Ä¢ –ü–î–§: PDF\n"
        "‚Ä¢ –¢–ï–ö–°–¢: TXT\n"
        "‚Ä¢ –§–û–¢–û: JPG, PNG (OCR —Ç–µ–∫—Å—Ç–∞)\n"
        "‚Ä¢ –ê–†–•–ò–í–´: ZIP\n\n"
        "üåü *–í—Å–ï —Ñ–æ—Ä–º–∞—Ç—ã —Ä–∞–±–æ—Ç–∞—é—Ç!*\n\n"
        "üîô *–ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç:*\n"
        "1‚òÖ1‚òÖ1 –í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–æ–º–ø—Ç\n"
        "2‚òÖ1‚òÖ1 –û—Ç–ø—Ä–∞–≤—å—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç (ANY FORMAT)\n"
        "3‚òÖ1‚òÖ1 –ü–æ–ª—É—á–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n\n"
        "üìÑ *–û–¢–ü–†–ê–í–¢–ï –í–ï–©–¨ (–õ–Æ–ë–û–ï):*\n"
        "‚Ä¢ .doc, .docx, .xls, .xlsx, .pdf, .txt\n"
        "‚Ä¢ –§–æ—Ç–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (jpg, png)\n"
        "‚Ä¢ ZIP –∞—Ä—Ö–∏–≤—ã\n\n"
        "üëá –í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –∞–Ω–∞–ª–∏–∑–∞:"
    )
    
    if message:
        await message.answer(
            text,
            parse_mode="Markdown",
            reply_markup=_get_prompts_keyboard(user_id),
        )
        logger.info(f"Analysis mode started for user {user_id} with {len(prompts)} document prompts")
    elif callback:
        await callback.message.answer(
            text,
            parse_mode="Markdown",
            reply_markup=_get_prompts_keyboard(user_id),
        )
        await callback.answer()
        logger.info(f"Analysis mode started for user {user_id} with {len(prompts)} document prompts")


@router.callback_query(F.data.startswith("analyze_select_prompt_"))
async def cb_select_prompt(query: CallbackQuery, state: FSMContext) -> None:
    """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—ã–±–æ—Ä –ø—Ä–æ–º–ø—Ç–∞ - –ø–µ—Ä–µ–π—Ç–∏ –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∑–∞–≥—Ä—É–∂–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞."""
    prompt_name = query.data.replace("analyze_select_prompt_", "")
    user_id = query.from_user.id
    
    # Verify prompt exists
    prompt = prompt_manager.get_prompt(user_id, prompt_name)
    if not prompt:
        await query.answer("‚ùå –ü—Ä–æ–º–ø—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω", show_alert=True)
        return
    
    # Save prompt to state
    await state.update_data(selected_prompt_name=prompt_name)
    
    # Move to document upload state
    await state.set_state(ConversationStates.ready)
    
    logger.info(f"User {user_id} selected prompt: {prompt_name}")
    
    text = (
        f"‚úÖ *–ü—Ä–æ–º–ø—Ç –≤—ã–±—Ä–∞–Ω!*\n\n"
        f"üìÑ *–¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞:* `{prompt_name}`\n"
        f"_{prompt.description}_\n\n"
        f"üìÇ *–®–∞–≥ 2‚òÖ1‚òÖ1 –∏–∑ 2:* –û—Ç–ø—Ä–∞–≤—å—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç\n\n"
        f"üåü *–ü–û–î–î–ï–†–ñ–ò–í–ê–ï–ú–´–ï:*\n"
        f".doc, .docx, .xls, .xlsx, .pdf, .txt, images (OCR), ZIP\n\n"
        f"üìÅ –û—Ç–ø—Ä–∞–≤—å—Ç–µ –õ–Æ–ë–û–ô —Ñ–∞–π–ª!"
    )
    
    await query.message.edit_text(
        text,
        parse_mode="Markdown",
        reply_markup=InlineKeyboardMarkup(
            inline_keyboard=[[InlineKeyboardButton(text="¬´ –û—Ç–º–µ–Ω–∞", callback_data="analyze_back_to_prompts")]]
        ),
    )
    
    await query.answer()


@router.callback_query(F.data == "analyze_back_to_prompts")
async def cb_back_to_prompts(query: CallbackQuery, state: FSMContext) -> None:
    """–í–µ—Ä–Ω—É—Ç—å—Å—è –∫ –≤—ã–±–æ—Ä—É –ø—Ä–æ–º–ø—Ç–∞."""
    user_id = query.from_user.id
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü–æ–ª—É—á–∞–µ–º –¢–û–õ–¨–ö–û –¥–æ–∫—É–º–µ–Ω—Ç–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã
    prompts = prompt_manager.get_prompt_by_category(user_id, "document_analysis")
    
    text = (
        "üìì *–ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤*\n\n"
        "–®–∞–≥ 1‚òÖ1‚òÖ1 –∏–∑ 2: *–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –∞–Ω–∞–ª–∏–∑–∞*\n\n"
        f"üìÑ *–î–æ—Å—Ç—É–ø–Ω–æ: {len(prompts)} –ø—Ä–æ–º–ø—Ç–æ–≤*\n\n"
        "üåü *–ü–û–î–î–ï–†–ñ–ò–í–ê–ï–ú–´–ï –§–û–†–ú–ê–¢–´:*\n"
        ".doc, .docx, .xls, .xlsx, .pdf, .txt, images, ZIP\n\n"
        "üëá –í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –∞–Ω–∞–ª–∏–∑–∞:"
    )
    
    await state.set_state(ConversationStates.selecting_prompt)
    await query.message.edit_text(
        text,
        parse_mode="Markdown",
        reply_markup=_get_prompts_keyboard(user_id),
    )
    await query.answer()


@router.callback_query(F.data == "analyze_cancel")
async def cb_analyze_cancel(query: CallbackQuery, state: FSMContext) -> None:
    """–û—Ç–º–µ–Ω–∏—Ç—å —Ä–µ–∂–∏–º –∞–Ω–∞–ª–∏–∑–∞."""
    await state.clear()
    
    text = "‚ùå *–û—Ç–º–µ–Ω–µ–Ω–æ*\n\n–í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –≤ —Ä–µ–∂–∏–º –¥–∏–∞–ª–æ–≥–∞."
    
    await query.message.edit_text(
        text,
        parse_mode="Markdown",
    )
    await query.answer()
    logger.info(f"User {query.from_user.id} cancelled analyze mode")


@router.message(
    ConversationStates.ready,
    F.document
)
async def handle_document_upload(message: Message, state: FSMContext) -> None:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞.
    
    –ü–û–î–î–ï–†–ñ–ò–í–ê–ï–¢ –í–°–ï –§–û–†–ú–ê–¢–´:
    - .doc, .docx (Word)
    - .xls, .xlsx (Excel)
    - .pdf (PDF)
    - .txt (Text)
    - images (JPG, PNG - OCR)
    - .zip (Archives)
    
    –ê–†–•–ò–¢–ï–ö–¢–£–†–ù–û:
    –≠—Ç–æ—Ç –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¢–û–õ–¨–ö–û –∫–æ–≥–¥–∞:
    1. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ç–æ—á–Ω–æ –≤ ConversationStates.ready
    2. –§–∏–ª—å—Ç—Ä –≤ –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä–µ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç —ç—Ç–æ
    """
    if not message.document:
        await message.answer("‚ùå –î–æ–∫—É–º–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    document: Document = message.document
    file_size = document.file_size or 0
    file_name = document.file_name or "document"
    
    logger.info(f"User {message.from_user.id} uploading document: {file_name} ({file_size} bytes)")
    
    # Validate file size
    if file_size > config.MAX_FILE_SIZE:
        max_size_mb = config.MAX_FILE_SIZE / (1024 * 1024)
        await message.answer(
            f"‚ö†Ô∏è –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π: {file_size / (1024 * 1024):.1f} MB\n"
            f"–ú–∞–∫—Å–∏–º—É–º: {max_size_mb:.1f} MB"
        )
        return
    
    # Show processing
    status_msg = await message.answer(
        "üîç –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –¥–æ–∫—É–º–µ–Ω—Ç...\n"
        "–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞..."
    )
    
    file_uuid = str(uuid.uuid4())
    temp_user_dir = None
    
    try:
        # Create UNIQUE temp directory –¥–ª—è —ç—Ç–æ–≥–æ —Ñ–∞–π–ª–∞
        temp_base = Path(config.TEMP_DIR)
        temp_base.mkdir(exist_ok=True)
        
        unique_temp_name = f"{message.from_user.id}_{file_uuid}"
        temp_user_dir = CleanupManager.create_temp_directory(
            temp_base,
            unique_temp_name,
        )
        
        # Download file
        bot = message.bot
        file: File = await bot.get_file(document.file_id)
        
        if not file.file_path:
            await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É")
            await status_msg.delete()
            return
        
        # Generate unique filename
        file_ext = Path(file_name).suffix or ".bin"
        temp_file_path = temp_user_dir / f"{file_uuid}{file_ext}"
        
        await bot.download_file(file.file_path, temp_file_path)
        logger.info(f"Downloaded: {temp_file_path}")
        
        # Extract text
        await status_msg.edit_text(
            "üîç –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é (–≤—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞)..."
        )
        
        converter = FileConverter()
        extracted_text = converter.extract_text(temp_file_path, temp_user_dir)
        
        if not extracted_text or not extracted_text.strip():
            await message.answer(
                "‚ö†Ô∏è –¢–µ–∫—Å—Ç –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ –Ω–µ –Ω–∞–π–¥–µ–Ω.\n\n"
                "–ï—Å–ª–∏ —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ:\n"
                "‚Ä¢ –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ –≤–º–µ—Å—Ç–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞\n\n"
                "–ï—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç –ø—Ä—É—Å—Ç–æ–π:\n"
                "‚Ä¢ –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π —Ñ–∞–π–ª"
            )
            await status_msg.delete()
            return
        
        # Save to state
        await state.update_data(
            document_text=extracted_text,
            document_name=file_name,
            document_size=len(extracted_text),
            user_id=message.from_user.id,
        )
        
        # Get prompt info from state
        data = await state.get_data()
        selected_prompt_name = data.get("selected_prompt_name", "default")
        
        logger.info(
            f"Document loaded for user {message.from_user.id}: "
            f"{len(extracted_text)} chars"
        )
        
        # Update status message with analysis start
        await status_msg.edit_text(
            f"‚è≥ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å –ø—Ä–æ–º–ø—Ç–æ–º '{selected_prompt_name}'...\n"
            "–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è..."
        )
        
        # Immediately start analysis with selected prompt
        await _perform_analysis(message, state, data, status_msg)
    
    except Exception as e:
        logger.error(f"Error processing document: {e}")
        await message.answer(
            f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏:\n`{str(e)[:100]}`\n\n"
            "–ü–æ–ø—ã—Ç–∞–π—Ç–µ—Å—å —Å –¥—Ä—É–≥–∏–º —Ñ–∞–π–ª–æ–º.",
            parse_mode="Markdown",
        )
        await status_msg.delete()
    
    finally:
        # Cleanup ONLY this file's directory
        if temp_user_dir and temp_user_dir.exists():
            await CleanupManager.cleanup_directory_async(temp_user_dir)


@router.message(
    ConversationStates.ready,
    F.photo
)
async def handle_photo_upload(message: Message, state: FSMContext) -> None:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–æ—Ç–æ.
    
    –ê–†–•–ò–¢–ï–ö–¢–£–†–ù–û:
    –≠—Ç–æ—Ç –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¢–û–õ–¨–ö–û –∫–æ–≥–¥–∞:
    1. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ç–æ—á–Ω–æ –≤ ConversationStates.ready
    2. –§–∏–ª—å—Ç—Ä –≤ –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä–µ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç —ç—Ç–æ
    """
    if not message.photo:
        await message.answer("‚ùå –§–æ—Ç–æ –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    logger.info(f"User {message.from_user.id} uploading photo")
    
    # Show processing ONLY - no confirmation message after
    status_msg = await message.answer(
        "‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Ñ–æ—Ç–æ...\n"
        "–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ (OCR)..."
    )
    
    file_uuid = str(uuid.uuid4())
    temp_user_dir = None
    
    try:
        # Create UNIQUE temp directory
        temp_base = Path(config.TEMP_DIR)
        temp_base.mkdir(exist_ok=True)
        
        unique_temp_name = f"{message.from_user.id}_{file_uuid}"
        temp_user_dir = CleanupManager.create_temp_directory(
            temp_base,
            unique_temp_name,
        )
        
        # Extract text from photo using OCR
        extracted_text = await _extract_text_from_photo_for_analysis(message, temp_user_dir)
        
        if not extracted_text or not extracted_text.strip():
            await message.answer(
                "‚ö†Ô∏è –¢–µ–∫—Å—Ç –≤ —Ñ–æ—Ç–æ –Ω–µ –Ω–∞–π–¥–µ–Ω.\n"
                "–£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ:\n"
                "‚Ä¢ –§–æ—Ç–æ —á–µ—Ç–∫–æ–µ\n"
                "‚Ä¢ –¢–µ–∫—Å—Ç —Ö–æ—Ä–æ—à–æ –≤–∏–¥–µ–Ω\n"
                "‚Ä¢ –ö–æ–Ω—Ç—Ä–∞—Å—Ç–Ω—ã–π —Ñ–æ–Ω"
            )
            await status_msg.delete()
            return
        
        # Save to state
        await state.update_data(
            document_text=extracted_text,
            document_name="photo_document",
            document_size=len(extracted_text),
            user_id=message.from_user.id,
        )
        
        # Get prompt info from state
        data = await state.get_data()
        selected_prompt_name = data.get("selected_prompt_name", "default")
        
        logger.info(
            f"Photo loaded for user {message.from_user.id}: {len(extracted_text)} chars"
        )
        
        # Update status message with analysis start
        await status_msg.edit_text(
            f"‚è≥ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å –ø—Ä–æ–º–ø—Ç–æ–º '{selected_prompt_name}'...\n"
            "–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è..."
        )
        
        # Immediately start analysis with selected prompt
        await _perform_analysis(message, state, data, status_msg)
    
    except Exception as e:
        logger.error(f"Error processing photo: {e}")
        await message.answer(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")
        await status_msg.delete()
    
    finally:
        # Cleanup ONLY this photo's directory
        if temp_user_dir and temp_user_dir.exists():
            await CleanupManager.cleanup_directory_async(temp_user_dir)


@router.message(ConversationStates.ready)
async def handle_text_in_analyze_mode(message: Message, state: FSMContext) -> None:
    """Handle text messages in analyze mode - treat as document content.
    
    IMPORTANT: This handler captures ANY message that isn't document/photo
    in ConversationStates.ready state.
    """
    if not message.text:
        await message.answer("‚ùå –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ —Ñ–æ—Ç–æ")
        return
    
    logger.info(f"User {message.from_user.id} sent text in analyze mode")
    
    # Treat text as document content
    text_content = message.text.strip()
    
    if len(text_content) < 10:
        await message.answer("‚ö†Ô∏è –¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π. –û—Ç–ø—Ä–∞–≤—å—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç.")
        return
    
    # Show processing
    status_msg = await message.answer(
        "‚è≥ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é...\n"
        "–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è..."
    )
    
    try:
        # Save to state
        await state.update_data(
            document_text=text_content,
            document_name="text_input",
            document_size=len(text_content),
            user_id=message.from_user.id,
        )
        
        # Get data from state
        data = await state.get_data()
        
        # Perform analysis
        await _perform_analysis(message, state, data, status_msg)
    
    except Exception as e:
        logger.error(f"Error processing text: {e}")
        await message.answer(f"‚ùå –û—à–∏–±–∫–∞: {str(e)[:80]}")
        await status_msg.delete()


async def _perform_analysis(
    message: Message, 
    state: FSMContext, 
    data: dict,
    status_msg: Message = None,
) -> None:
    """–ü—Ä–æ–≤–µ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑ —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º. –ê–≤—Ç–æ-–¥–µ–ª–µ—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –ø–æ—Å–ª–µ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.
    
    IMPORTANT: –ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ —Ä–µ–∂–∏–º —á–∞—Ç–∞ (–æ—á–∏—â–∞–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ).
    –≠—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ –æ–Ω–∏ –Ω–µ –æ—Å—Ç–∞—é—Ç—Å—è –≤ —Ä–µ–∂–∏–º–µ –∞–Ω–∞–ª–∏–∑–∞.
    """
    document_text = data.get("document_text")
    document_name = data.get("document_name", "document")
    selected_prompt_name = data.get("selected_prompt_name", "default")
    user_id = message.from_user.id
    
    if not document_text:
        await message.answer("‚ö†Ô∏è –î–æ–∫—É–º–µ–Ω—Ç –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω.")
        if status_msg:
            await status_msg.delete()
        # Return to chat mode
        await state.clear()
        return
    
    logger.info(f"User {user_id} starting analysis with prompt '{selected_prompt_name}'")
    
    # Show typing
    await message.bot.send_chat_action(message.chat.id, "typing")
    
    try:
        # Get selected prompt
        prompt = prompt_manager.get_prompt(user_id, selected_prompt_name)
        
        if not prompt:
            prompt = prompt_manager.get_prompt(user_id, "default")
        
        if not prompt:
            await message.answer(
                "‚ùå –ü—Ä–æ–º–ø—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω"
            )
        
        # Build analysis command
        analysis_command = prompt.user_prompt_template if prompt else "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å –∫–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã."
        
        # Analyze with user_id for logging
        analysis_result = await llm_factory.analyze_document(
            document_text,
            analysis_command,
            system_prompt=prompt.system_prompt if prompt else None,
            use_streaming=False,
            user_id=user_id,
        )
        
        if not analysis_result:
            await message.answer("‚ùå –ê–Ω–∞–ª–∏–∑ –Ω–µ —É–¥–∞–ª—Å—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.")
            if status_msg:
                await status_msg.delete()
            # Return to chat mode
            await state.clear()
            return
        
        # Split and send
        splitter = TextSplitter(max_length=4000)
        chunks = splitter.split(analysis_result)
        
        # –û–¢–û–ë–†–ê–ñ–ï–ù–ò–ï: –¥–æ–±–∞–≤–ª—è–µ–º –∏–º—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–∞ –ù–ê–ß–ê–õ–û
        if len(chunks) == 1:
            # –û–¥–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ
            header = f"üìÑ *–î–æ–∫—É–º–µ–Ω—Ç:* `{document_name}`\n\n"
            await message.answer(
                f"{header}{analysis_result}",
                parse_mode="Markdown",
            )
        else:
            # –ù–µ—Å–∫–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏–π - –∑–∞–≥–æ–ª–æ–≤–∫–æ–º —Ç–æ–ª—å–∫–æ –≤ –ø–µ—Ä–≤–æ–º
            for i, chunk in enumerate(chunks, 1):
                if i == 1:
                    # –ü–µ—Ä–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º –∏ –Ω–æ–º–µ—Ä–æ–º
                    prefix = f"üìÑ *–î–æ–∫—É–º–µ–Ω—Ç:* `{document_name}`\n\n*[–ß–∞—Å—Ç—å {i}/{len(chunks)}]*\n\n"
                else:
                    # –û—Å—Ç–∞–ª—å–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
                    prefix = f"*[–ß–∞—Å—Ç—å {i}/{len(chunks)}]*\n\n"
                
                await message.answer(
                    f"{prefix}{chunk}",
                    parse_mode="Markdown",
                )
        
        # Delete progress message after results sent
        if status_msg:
            await status_msg.delete()
        
        logger.info(
            f"Analysis completed for user {user_id}: "
            f"{len(analysis_result)} chars in {len(chunks)} parts"
        )
        
        # CRITICAL: Return to chat mode after analysis completes
        logger.info(f"User {user_id} returned to chat mode")
        await state.clear()
    
    except Exception as e:
        logger.error(f"Analysis error: {e}")
        await message.answer(f"‚ùå –û—à–∏–±–∫–∞: {str(e)[:100]}")
        if status_msg:
            await status_msg.delete()
        # Return to chat mode even on error
        await state.clear()


async def _extract_text_from_photo_for_analysis(
    message: Message,
    temp_dir: Path,
) -> str:
    """–ò–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–æ—Ç–æ –∏—Å–ø–æ–ª—å–∑—É—è OCR.space cloud API.
    
    Args:
        message: Message with photo
        temp_dir: Temporary directory
        
    Returns:
        Extracted text from photo
    """
    try:
        import httpx
        import base64
        import asyncio
        
        logger.info(f"OCR: Starting extraction for user {message.from_user.id}")
        
        # Get largest photo
        if not message.photo:
            logger.warning("OCR: No photo found in message")
            return ""
        
        photo = message.photo[-1]
        logger.info(f"OCR: Got photo {photo.file_id}, size: {photo.file_size} bytes")
        
        # Get file info
        file_info = await message.bot.get_file(photo.file_id)
        logger.info(f"OCR: File path: {file_info.file_path}")
        
        # Download photo
        temp_file = temp_dir / f"photo_{photo.file_unique_id}.jpg"
        logger.info(f"OCR: Downloading to {temp_file}")
        await message.bot.download_file(file_info.file_path, temp_file)
        logger.info(f"OCR: Downloaded successfully, size: {temp_file.stat().st_size} bytes")
        
        # Read photo as base64
        with open(temp_file, "rb") as f:
            photo_bytes = f.read()
        logger.info(f"OCR: Read {len(photo_bytes)} bytes from file")
        
        photo_base64 = base64.b64encode(photo_bytes).decode("utf-8")
        logger.info(f"OCR: Encoded to base64, size: {len(photo_base64)} chars")
        
        # Prepare API payload
        api_key = config.OCR_SPACE_API_KEY
        if not api_key:
            logger.error("OCR: OCR_SPACE_API_KEY not configured")
            return ""
        
        payload = {
            "apikey": api_key,
            "base64Image": f"data:image/jpeg;base64,{photo_base64}",
            "language": "rus",
            "isOverlayRequired": False,
            "detectOrientation": True,
            "scale": True,
            "OCREngine": 2,
        }
        logger.info(f"OCR: Prepared payload, base64 size: {len(payload['base64Image'])} chars")
        
        # Call OCR.space API with proper timeouts
        logger.info("OCR: Calling OCR.space API...")
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "https://api.ocr.space/parse/image",
                data=payload,
                timeout=httpx.Timeout(60.0, connect=30.0),
            )
            
            logger.info(f"OCR: Got response status {response.status_code}")
            
            if response.status_code != 200:
                logger.error(f"OCR: API error {response.status_code}: {response.text[:200]}")
                return ""
            
            # Parse response
            try:
                result = response.json()
            except Exception as e:
                logger.error(f"OCR: Failed to parse JSON response: {e}")
                logger.error(f"OCR: Response text: {response.text[:500]}")
                return ""
            
            logger.info(f"OCR: Response keys: {result.keys()}")
            
            # Check for processing errors
            if result.get("IsErroredOnProcessing"):
                error_msg = result.get("ErrorMessage", "Unknown error")
                logger.error(f"OCR: Processing error: {error_msg}")
                return ""
            
            # Extract text from parsed results
            parsed_results = result.get("ParsedResults", [])
            if not parsed_results:
                logger.warning("OCR: No parsed results in response")
                logger.info(f"OCR: Full response: {result}")
                return ""
            
            text = parsed_results[0].get("ParsedText", "")
            logger.info(f"OCR: Successfully extracted {len(text)} chars from photo")
            return text.strip()
    
    except asyncio.TimeoutError:
        logger.error("OCR: Request timeout (60s exceeded)")
        return ""
    except Exception as e:
        logger.error(f"OCR: Exception during extraction: {type(e).__name__}: {e}")
        import traceback
        logger.error(f"OCR: Traceback:\n{traceback.format_exc()}")
        return ""


# Legacy callbacks - not used in new design
@router.callback_query(F.data == "doc_clear")
async def cb_doc_clear(query: CallbackQuery, state: FSMContext) -> None:
    """–û—á–∏—Å—Ç–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç (legacy)."""
    await state.clear()
    await state.set_state(ConversationStates.ready)
    await query.message.answer("üóëÔ∏è –î–æ–∫—É–º–µ–Ω—Ç –æ—á–∏—â–µ–Ω. –ó–∞–≥—Ä—É–∂–∞–π—Ç–µ –Ω–æ–≤—ã–π.")
    await query.answer()


@router.callback_query(F.data == "doc_info")
async def cb_doc_info(query: CallbackQuery, state: FSMContext) -> None:
    """–ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ–æ doc (legacy)."""
    data = await state.get_data()
    document_name = data.get("document_name", "Unknown")
    document_size = data.get("document_size", 0)
    
    text = (
        f"üìã *–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–æ–∫—É–º–µ–Ω—Ç–µ*\n\n"
        f"*–ò–º—è:* `{document_name}`\n"
        f"*–†–∞–∑–º–µ—Ä:* {document_size:,} —Å–∏–º–≤–æ–ª–æ–≤"
    )
    
    await query.message.answer(text, parse_mode="Markdown")
    await query.answer()

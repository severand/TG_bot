"""–ö–æ–Ω–≤–µ—Ä—Å–∞—Ü–∏—è –º–æ–¥–µ–ª —Ö–∞–Ω–¥–ª–µ—Ä—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.

POLNAYA PODDERZHKA:
- Word: .docx, .doc
- Excel: .xlsx, .xls  
- PDF
- Text: .txt
- Images: .jpg, .png (OCR - LOCAL TESSERACT)

UPDATED 2025-12-28 23:22:
- FIXED: /analyze now clears state BEFORE setting new state
- ADDED: Better logging for state transitions
- FIXED: Proper cancellation returns to chat mode

UPDATED 2025-12-28 22:56:
- FIXED: Text preview moved to logs ONLY (not displayed to user)
- ADDED: OCR quality check (detects gibberish/handwriting)
- IMPROVED: Better error messages for OCR failures
- FIXED: JPG detection and handling

UPDATED 2025-12-28 22:49:
- ADDED: OCR text preview (first 300 chars) before analysis
- User can see EXACTLY what OCR extracted
- Better UX - no mystery what got recognized

UPDATED 2025-12-28 22:35:
- FIXED: EASYOCR_AVAILABLE variable always defined
- FIXED: Auto-detect Tesseract path on Windows
- Added explicit path configuration for Windows

UPDATED 2025-12-28 21:52:
- REPLACED OCR.space with LOCAL Tesseract (NO SSL issues!)
- Added EasyOCR as fallback if Tesseract not installed
- 100% offline capable - no API calls needed

Handles document analysis and user prompts for interactive conversation.
"""

import logging
import uuid
import os
from pathlib import Path

from aiogram import Router, F
from aiogram.filters import Command, StateFilter
from aiogram.types import Message, Document, File, CallbackQuery, InlineKeyboardButton, InlineKeyboardMarkup
from aiogram.fsm.context import FSMContext
from aiogram.utils.keyboard import InlineKeyboardBuilder

from app.config import get_settings
from app.states.conversation import ConversationStates
from app.states.chat import ChatStates
from app.services.file_processing.converter import FileConverter
from app.services.llm.llm_factory import LLMFactory
from app.services.prompts.prompt_manager import PromptManager
from app.utils.text_splitter import TextSplitter
from app.utils.cleanup import CleanupManager

logger = logging.getLogger(__name__)

router = Router()
config = get_settings()
prompt_manager = PromptManager()
llm_factory = LLMFactory(
    primary_provider=config.LLM_PROVIDER,
    openai_api_key=config.OPENAI_API_KEY or None,
    openai_model=config.OPENAI_MODEL,
    replicate_api_token=config.REPLICATE_API_TOKEN or None,
    replicate_model=config.REPLICATE_MODEL,
)

# ============================================================================
# OCR INITIALIZATION - Try to import OCR libraries
# ============================================================================
TESSERACT_AVAILABLE = False
EASYOCR_AVAILABLE = False
_ocr_reader = None

# Try Tesseract first
try:
    import pytesseract
    from PIL import Image
    
    # Windows: Auto-detect Tesseract installation path
    if os.name == 'nt':  # Windows
        possible_paths = [
            r'C:\Program Files\Tesseract-OCR\tesseract.exe',
            r'C:\Program Files (x86)\Tesseract-OCR\tesseract.exe',
            r'C:\Tesseract-OCR\tesseract.exe',
        ]
        for path in possible_paths:
            if os.path.exists(path):
                pytesseract.pytesseract.tesseract_cmd = path
                logger.info(f"[OCR] Found Tesseract at: {path}")
                break
    
    # Test if Tesseract actually works
    pytesseract.get_tesseract_version()
    TESSERACT_AVAILABLE = True
    logger.info("[OCR] ‚úÖ Tesseract available - will use LOCAL OCR")
except Exception as e:
    logger.warning(f"[OCR] ‚ö†Ô∏è Tesseract NOT available: {e}")
    TESSERACT_AVAILABLE = False

# Try EasyOCR as fallback
try:
    import easyocr
    EASYOCR_AVAILABLE = True
    logger.info("[OCR] ‚úÖ EasyOCR available as fallback")
except ImportError:
    EASYOCR_AVAILABLE = False
    logger.warning("[OCR] ‚ö†Ô∏è EasyOCR NOT available")

# Final status
if not TESSERACT_AVAILABLE and not EASYOCR_AVAILABLE:
    logger.error("[OCR] ‚ùå NO OCR ENGINE AVAILABLE!")
    logger.error("[OCR] Install Tesseract: https://github.com/UB-Mannheim/tesseract/wiki")
    logger.error("[OCR] Or run: pip install easyocr")


def _get_prompts_keyboard(user_id: int) -> InlineKeyboardMarkup:
    """–ü–æ–ª—É—á–∏—Ç—å –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Å ONLY –¥–æ–∫—É–º–µ–Ω—Ç–Ω—ã–º –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–º–ø—Ç–∞–º–∏ - 2 –∫–Ω–æ–ø–∫–∏ –≤ —Å—Ç—Ä–æ–∫–µ."""
    # –õ–æ–∞–¥–∏–º –ø—Ä–æ–º–ø—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    prompt_manager.load_user_prompts(user_id)
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü–æ–ª—É—á–∞–µ–º –¢–û–õ–¨–ö–û –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    prompts = prompt_manager.get_prompt_by_category(user_id, "document_analysis")
    
    logger.debug(f"User {user_id}: Loading {len(prompts)} DOCUMENT ANALYSIS prompts")
    
    builder = InlineKeyboardBuilder()
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫–∏ —Ç–æ–ª—å–∫–æ –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤
    for name in sorted(prompts.keys()):
        prompt = prompts[name]
        button_text = f"{prompt.description[:40]}"
        builder.button(
            text=button_text,
            callback_data=f"analyze_select_prompt_{name}"
        )
    
    # –ö–Ω–æ–ø–∫–∞ –æ—Ç–º–µ–Ω—ã
    builder.button(text="¬´ –û—Ç–º–µ–Ω–∞", callback_data="analyze_cancel")
    builder.adjust(2)  # 2 –∫–Ω–æ–ø–∫–∏ –≤ —Ä—è–¥—É
    
    return builder.as_markup()


@router.message(Command("analyze"))
async def cmd_analyze(message: Message, state: FSMContext) -> None:
    """–ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∂–∏–º –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.
    
    CRITICAL FIX 2025-12-28 23:22:
    - MUST clear state FIRST, then set new state
    - This prevents conflicts between modes
    """
    current_state = await state.get_state()
    user_id = message.from_user.id
    logger.info(f"User {user_id} /analyze (previous state: {current_state})")
    
    # –û–ß–ï–†–ï–î–ù–û–°–¢–¨ CRITICAL!
    # –ù–ï –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å—Ä–∞–∑—É!
    # –°–ù–ê–ß–ê–õ–ê –æ—á–∏—Å—Ç–∏–º
    await state.clear()
    logger.debug(f"Cleared all previous states for user {user_id}")
    
    # –ù–ï –û–ß–û–ù–¨ –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ù–û–í–û–ï
    await state.set_state(ConversationStates.selecting_prompt)
    logger.debug(f"Set ConversationStates.selecting_prompt for user {user_id}")
    
    await start_analyze_mode(message=message, state=state)


async def start_analyze_mode(callback: CallbackQuery = None, message: Message = None, state: FSMContext = None) -> None:
    """–ù–∞—á–∞—Ç—å –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.
    
    NEW: –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –≤—ã–±–æ—Ä –ø—Ä–æ–º–ø—Ç–∞ –í –ü–ï–†–í–´–•, —Ç–æ –≤–∞–ø—Ä–æ—Å–∏–∏ –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞.
    –¢–û–õ–¨–ö–û –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤!
    """
    if state is None:
        logger.error("state is None in start_analyze_mode")
        return
    
    user_id = message.from_user.id if message else callback.from_user.id if callback else None
    
    if not user_id:
        logger.error("Cannot determine user_id")
        return
    
    # Load user prompts
    prompt_manager.load_user_prompts(user_id)
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü–æ–ª—É—á–∞–µ–º –¢–û–õ–¨–ö–û –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤
    prompts = prompt_manager.get_prompt_by_category(user_id, "document_analysis")
    
    await state.set_state(ConversationStates.selecting_prompt)
    
    text = (
        "üìì *–ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤*\n\n"
        "–®–∞–≥ 1 –∏–∑ 2: *–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –∞–Ω–∞–ª–∏–∑–∞*\n\n"
        f"üìÑ *–î–æ—Å—Ç—É–ø–Ω–æ: {len(prompts)} –ø—Ä–æ–º–ø—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞*\n\n"
        "üîô *–ü–û–î–î–ï–†–ñ–ò–í–ê–ï–ú–´–ï –§–û–†–ú–ê–¢–´:*\n"
        "‚Ä¢ Word: .docx, .doc\n"
        "‚Ä¢ Excel: .xlsx, .xls\n"
        "‚Ä¢ PDF: .pdf\n"
        "‚Ä¢ –¢–µ–∫—Å—Ç: .txt\n"
        "‚Ä¢ –§–æ—Ç–æ: JPG, PNG (OCR)\n"
        "‚Ä¢ –ê—Ä—Ö–∏–≤—ã: ZIP\n\n"
        "üëá –í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –∞–Ω–∞–ª–∏–∑–∞:"
    )
    
    if message:
        await message.answer(
            text,
            parse_mode="Markdown",
            reply_markup=_get_prompts_keyboard(user_id),
        )
        logger.info(f"Analysis mode started for user {user_id} with {len(prompts)} document prompts")
    elif callback:
        await callback.message.answer(
            text,
            parse_mode="Markdown",
            reply_markup=_get_prompts_keyboard(user_id),
        )
        await callback.answer()
        logger.info(f"Analysis mode started for user {user_id} with {len(prompts)} document prompts")


@router.callback_query(F.data.startswith("analyze_select_prompt_"))
async def cb_select_prompt(query: CallbackQuery, state: FSMContext) -> None:
    """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—ã–±–æ—Ä –ø—Ä–æ–º–ø—Ç–∞ - –ø–µ—Ä–µ–π—Ç–∏ –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∑–∞–≥—Ä—É–∂–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞."""
    prompt_name = query.data.replace("analyze_select_prompt_", "")
    user_id = query.from_user.id
    
    # Verify prompt exists
    prompt = prompt_manager.get_prompt(user_id, prompt_name)
    if not prompt:
        await query.answer("‚ùå –ü—Ä–æ–º–ø—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω", show_alert=True)
        return
    
    # Save prompt to state
    await state.update_data(selected_prompt_name=prompt_name)
    
    # Move to document upload state
    await state.set_state(ConversationStates.ready)
    
    logger.info(f"User {user_id} selected prompt: {prompt_name}")
    
    text = (
        f"‚úÖ *–ü—Ä–æ–º–ø—Ç –≤—ã–±—Ä–∞–Ω!*\n\n"
        f"üìÑ *–¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞:* `{prompt_name}`\n"
        f"_{prompt.description}_\n\n"
        f"üìÇ *–®–∞–≥ 2 –∏–∑ 2:* –û—Ç–ø—Ä–∞–≤—å—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç\n\n"
        f"üåü *–ü–û–î–î–ï–†–ñ–ò–í–ê–ï–ú–´–ï:*\n"
        f".doc, .docx, .xls, .xlsx, .pdf, .txt, images (OCR), ZIP\n\n"
        f"üìÅ –û—Ç–ø—Ä–∞–≤—å—Ç–µ –õ–Æ–ë–û–ô —Ñ–∞–π–ª!"
    )
    
    await query.message.edit_text(
        text,
        parse_mode="Markdown",
        reply_markup=InlineKeyboardMarkup(
            inline_keyboard=[[InlineKeyboardButton(text="¬´ –û—Ç–º–µ–Ω–∞", callback_data="analyze_back_to_prompts")]]
        ),
    )
    
    await query.answer()


@router.callback_query(F.data == "analyze_back_to_prompts")
async def cb_back_to_prompts(query: CallbackQuery, state: FSMContext) -> None:
    """–í–µ—Ä–Ω—É—Ç—å—Å—è –∫ –≤—ã–±–æ—Ä—É –ø—Ä–æ–º–ø—Ç–∞."""
    user_id = query.from_user.id
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü–æ–ª—É—á–∞–µ–º –¢–û–õ–¨–ö–û –¥–æ–∫—É–º–µ–Ω—Ç–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã
    prompts = prompt_manager.get_prompt_by_category(user_id, "document_analysis")
    
    text = (
        "üìì *–ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤*\n\n"
        "–®–∞–≥ 1 –∏–∑ 2: *–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –∞–Ω–∞–ª–∏–∑–∞*\n\n"
        f"üìÑ *–î–æ—Å—Ç—É–ø–Ω–æ: {len(prompts)} –ø—Ä–æ–º–ø—Ç–æ–≤*\n\n"
        "üåü *–ü–û–î–î–ï–†–ñ–ò–í–ê–ï–ú–´–ï –§–û–†–ú–ê–¢–´:*\n"
        ".doc, .docx, .xls, .xlsx, .pdf, .txt, images, ZIP\n\n"
        "üëá –í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –∞–Ω–∞–ª–∏–∑–∞:"
    )
    
    await state.set_state(ConversationStates.selecting_prompt)
    await query.message.edit_text(
        text,
        parse_mode="Markdown",
        reply_markup=_get_prompts_keyboard(user_id),
    )
    await query.answer()


@router.callback_query(F.data == "analyze_cancel")
async def cb_analyze_cancel(query: CallbackQuery, state: FSMContext) -> None:
    """–û—Ç–º–µ–Ω–∏—Ç—å —Ä–µ–∂–∏–º –∞–Ω–∞–ª–∏–∑–∞ –∏ –í–ï–†–ù–£–¢–°–Ø –í –ó–ê–ì–û–í–û–†.
    
    CRITICAL FIX:
    - Must clear state
    - Must set ChatStates.chatting
    - This is essential for mode switching!
    """
    user_id = query.from_user.id
    logger.info(f"User {user_id} cancelled analyze mode")
    
    # –û–ß–ï–†–ï–î–ù–û–°–¢–¨ CRITICAL!
    # –û–ß–ò—Å—Ç–∏–º –±—ã–≤—à–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    await state.clear()
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–µ–∂–∏–º –¥–∏–∞–ª–æ–≥–∞
    await state.set_state(ChatStates.chatting)
    logger.debug(f"Cleared analyze state and set ChatStates.chatting for user {user_id}")
    
    text = "‚ùå *–û—Ç–º–µ–Ω–µ–Ω–æ*\n\n–í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –≤ —Ä–µ–∂–∏–º –¥–∏–∞–ª–æ–≥–∞."
    
    await query.message.edit_text(
        text,
        parse_mode="Markdown",
    )
    await query.answer()


# NOTE: All other handlers (handle_document_upload, handle_photo_upload, etc.) are omitted here
# but should remain in the actual file. Only showing the state management fixes for /analyze command
# and cancellation flow which were the core issues.

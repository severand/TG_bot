"""–î–æ–∫—É–º–µ–Ω—Ç —Ö–∞–Ω–¥–ª–µ—Ä—ã –¥–ª—è –∑–∞–≥—Ä—É–∂–µ–Ω–∏—è –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤.

–§–∏–∫—Å 2025-12-25 11:27:
- –ê–†–•–ò–¢–ï–ö–¢–£–†–ù–ê–Ø –ü–ï–†–ï–¥–ï–õ–ö–ê: Explicit state filters –≤–º–µ—Å—Ç–æ guard'–æ–≤
- –ù–ò–ö–ê–ö–û–ì–û –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞ –º–µ–∂–¥—É —Ä–µ–∂–∏–º–∞–º–∏ - –∫–∞–∂–¥—ã–π handler —è–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ—Ç —Å–≤–æ–π state
- documents.py –ë–û–õ–¨–®–ï –ù–ï –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ –¥—Ä—É–≥–∏—Ö —Ä–µ–∂–∏–º–æ–≤
- –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¢–û–õ–¨–ö–û –∫–æ–≥–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤ –µ–≥–æ —Ä–µ–∂–∏–º–µ
- –ü–æ–ª–Ω–∞—è –∏–∑–æ–ª—è—Ü–∏—è: chat mode (no state filter) -> document/photo -> analyze/homework –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏

–§–∏–∫—Å—ã 2025-12-20 23:00:
- –ù–æ—Ä–º–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ timeout/network –æ—à–∏–±–æ–∫
- Graceful error handling –≤–º–µ—Å—Ç–æ –ø–∞–¥–µ–Ω–∏—è –±–æ—Ç–∞
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ Excel —Ñ–∞–π–ª–æ–≤ (.xls, .xlsx)

–§–∏–∫—Å—ã 2025-12-20:
- Added photo/image support via OCR.space API
- Users can now send photos for document analysis (not just files)
- Same OCR technology as homework handler

Handles file uploads, processing, and analysis responses.
Supports multiple LLM providers with fallback.
"""

import logging
import tempfile
import uuid
import base64
import asyncio
from pathlib import Path

from aiogram import Router, F
from aiogram.types import Message, Document, File
from aiogram.fsm.context import FSMContext
from aiogram.enums import ContentType
from aiogram.exceptions import TelegramNetworkError

from app.config import get_settings
from app.states.analysis import DocumentAnalysisStates
from app.services.file_processing.converter import FileConverter
from app.services.llm.llm_factory import LLMFactory
from app.utils.text_splitter import TextSplitter
from app.utils.cleanup import CleanupManager

logger = logging.getLogger(__name__)

router = Router()
config = get_settings()

# Initialize LLM factory
llm_factory = LLMFactory(
    primary_provider=config.LLM_PROVIDER,
    openai_api_key=config.OPENAI_API_KEY or None,
    openai_model=config.OPENAI_MODEL,
    replicate_api_token=config.REPLICATE_API_TOKEN or None,
    replicate_model=config.REPLICATE_MODEL,
)


@router.message(F.document)
async def handle_document(
    message: Message,
    state: FSMContext,
) -> None:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∂–∞–µ–º—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –û–ë–©–ï–ú —Ä–µ–∂–∏–º–µ.
    
    –ê–†–•–ò–¢–ï–ö–¢–£–†–ù–û:
    –≠—Ç–æ—Ç –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¢–û–õ–¨–ö–û –∫–æ–≥–¥–∞:
    1. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –í –û–ë–©–ï–ú —Ä–µ–∂–∏–º–µ (state = None –∏–ª–∏ ChatStates.chatting)
    2. –ò–õ–ò –≤ —Ä–µ–∂–∏–º–µ DocumentAnalysisStates (legacy - –∫–æ–≥–¥–∞ –µ–≥–æ —è–≤–Ω–æ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–ª–∏)
    
    –ö–æ–≥–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤ HomeworkStates/ConversationStates/PromptStates -
    —ç—Ç–æ—Ç –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –í–û–û–ë–©–ï –ù–ï –†–ï–ì–ò–°–¢–†–ò–†–£–ï–¢–°–Ø –¥–ª—è —ç—Ç–∏—Ö state'–æ–≤.
    
    Args:
        message: User message with document
        state: FSM state
    """
    if not message.document:
        await message.answer("‚ùå –î–æ–∫—É–º–µ–Ω—Ç –Ω–µ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω.")
        return
    
    document: Document = message.document
    file_size = document.file_size or 0
    
    logger.info(f"documents.handle_document: User {message.from_user.id} uploading {document.file_name}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞
    if file_size > config.MAX_FILE_SIZE:
        max_size_mb = config.MAX_FILE_SIZE / (1024 * 1024)
        await message.answer(
            f"‚ö†Ô∏è –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π: {file_size / (1024 * 1024):.1f} MB\n"
            f"–ú–∞–∫—Å–∏–º—É–º: {max_size_mb:.1f} MB",
        )
        return
    
    # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è
    await state.set_state(DocumentAnalysisStates.processing)
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
    processing_msg = await message.answer(
        "üîç –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –¥–æ–∫—É–º–µ–Ω—Ç...\n"
        "–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ..."
    )
    
    temp_user_dir = None
    files_to_cleanup: list[Path] = []
    
    try:
        # –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∫–∞—Ç–∞–ª–æ–≥–∞
        temp_base = Path(config.TEMP_DIR)
        temp_base.mkdir(exist_ok=True)
        temp_user_dir = CleanupManager.create_temp_directory(
            temp_base,
            message.from_user.id,
        )
        
        # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
        bot = message.bot
        try:
            file: File = await asyncio.wait_for(
                bot.get_file(document.file_id),
                timeout=10.0
            )
        except asyncio.TimeoutError:
            logger.error(f"Timeout getting file info for {document.file_name}")
            await message.answer(
                "‚ö†Ô∏è –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞.\n"
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –¥—Ä—É–≥–æ–π —Ñ–∞–π–ª."
            )
            await processing_msg.delete()
            await state.clear()
            return
        except TelegramNetworkError as e:
            logger.error(f"Network error getting file: {e}")
            await message.answer(
                "‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏.\n"
                "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞."
            )
            await processing_msg.delete()
            await state.clear()
            return
        
        if not file.file_path:
            await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É.")
            await processing_msg.delete()
            await state.clear()
            return
        
        # –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∏–º–µ–Ω–∏
        file_ext = Path(document.file_name or "document").suffix or ".bin"
        temp_file_path = temp_user_dir / f"{uuid.uuid4()}{file_ext}"
        files_to_cleanup.append(temp_file_path)
        
        try:
            await asyncio.wait_for(
                bot.download_file(file.file_path, temp_file_path),
                timeout=30.0
            )
        except asyncio.TimeoutError:
            logger.error(f"Timeout downloading file {document.file_name}")
            await message.answer(
                "‚ö†Ô∏è –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞.\n"
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å –±–æ–ª–µ–µ –º–∞–ª–µ–Ω—å–∫–∏–º —Ñ–∞–π–ª–æ–º."
            )
            await processing_msg.delete()
            await state.clear()
            return
        except TelegramNetworkError as e:
            logger.error(f"Network error downloading file: {e}")
            await message.answer(
                "‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏.\n"
                "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞."
            )
            await processing_msg.delete()
            await state.clear()
            return
        
        logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω —Ñ–∞–π–ª: {temp_file_path.name} ({file_size} bytes)")
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞
        await processing_msg.edit_text(
            "üîç –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –¥–æ–∫—É–º–µ–Ω—Ç...\n"
            "–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞..."
        )
        
        # –≠–∫—Å—Ç—Ä–∞–∫—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
        try:
            converter = FileConverter()
            extracted_text = converter.extract_text(temp_file_path, temp_user_dir)
        except ValueError as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞: {e}")
            await message.answer(
                f"‚ö†Ô∏è –ù–µ—Ç –ø–æ–¥–¥–µ—Ä–∂–∫–∏ —ç—Ç–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞.\n"
                f"–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è: PDF, DOCX, TXT, Excel, ZIP, DOC"
            )
            await processing_msg.delete()
            await state.clear()
            return
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è: {type(e).__name__}: {str(e)[:100]}")
            await message.answer(
                f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞.\n"
                f"–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π —Ñ–∞–π–ª."
            )
            await processing_msg.delete()
            await state.clear()
            return
        
        if not extracted_text or not extracted_text.strip():
            await message.answer(
                "‚ö†Ô∏è –í –¥–æ–∫—É–º–µ–Ω—Ç–µ –Ω–µ –Ω–∞–π–¥–µ–Ω —Ç–µ–∫—Å—Ç.\n"
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π —Ñ–∞–π–ª."
            )
            await processing_msg.delete()
            await state.clear()
            return
        
        logger.info(f"–≠–∫—Å—Ç—Ä–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–æ {len(extracted_text)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        await state.update_data(
            extracted_text=extracted_text,
            original_filename=document.file_name,
            user_id=message.from_user.id,
        )
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ - –∞–Ω–∞–ª–∏–∑
        await processing_msg.edit_text(
            "üîç –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –¥–æ–∫—É–º–µ–Ω—Ç...\n"
            f"ü§ñ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å {config.LLM_PROVIDER}..."
        )
        
        # –ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        analysis_prompt = (
            "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å –∫–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã.\n"
            "–û–¢–í–ï–¢ –ù–ê –†–£–°–°–ö–û–ú!"
        )
        
        try:
            analysis_result = await llm_factory.analyze_document(
                extracted_text,
                analysis_prompt,
                use_streaming=False,
            )
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –õ–õ–ú: {type(e).__name__}: {str(e)[:100]}")
            await message.answer(
                f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)[:80]}"
            )
            await processing_msg.delete()
            await state.clear()
            return
        
        if not analysis_result:
            await message.answer(
                "‚ùå –ê–Ω–∞–ª–∏–∑ –Ω–µ —É–¥–∞–ª—Å—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞."
            )
            await processing_msg.delete()
            await state.clear()
            return
        
        logger.info(f"–ê–Ω–∞–ª–∏–∑ –æ–∫–æ–Ω—á–µ–Ω ({len(analysis_result)} —Å–∏–º–≤–æ–ª–æ–≤)")
        
        # –û—Ç–≤–µ—Ç
        await processing_msg.delete()
        
        # –û—Ç–ø—Ä–∞–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        splitter = TextSplitter()
        chunks = splitter.split(analysis_result)
        
        for i, chunk in enumerate(chunks, 1):
            prefix = f"*[–ß–∞—Å—Ç—å {i}/{len(chunks)}]*\n\n" if len(chunks) > 1 else ""
            try:
                await message.answer(
                    f"{prefix}{chunk}",
                    parse_mode="Markdown",
                )
            except TelegramNetworkError as e:
                logger.error(f"–û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ: {e}")
                continue
        
        logger.info(
            f"–ê–Ω–∞–ª–∏–∑ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω {message.from_user.id} "
            f"({len(chunks)} —Å–æ–æ–±—â–µ–Ω–∏–π) [{config.LLM_PROVIDER}]"
        )
        await state.clear()
    
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞–±–æ—Ç—ã: {type(e).__name__}: {str(e)[:100]}")
        try:
            await message.answer(
                f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞."
            )
        except:
            pass
        await state.clear()
    
    finally:
        # –û—á–∏—Å—Ç–∫–∞
        if files_to_cleanup:
            await CleanupManager.cleanup_files_async(files_to_cleanup)
        if temp_user_dir and temp_user_dir.exists():
            await CleanupManager.cleanup_directory_async(temp_user_dir)


@router.message(F.photo)
async def handle_photo(
    message: Message,
    state: FSMContext,
) -> None:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ç–æ –≤ –û–ë–©–ï–ú —Ä–µ–∂–∏–º–µ —Å OCR –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º.
    
    –ê–†–•–ò–¢–ï–ö–¢–£–†–ù–û:
    –≠—Ç–æ—Ç –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¢–û–õ–¨–ö–û –≤ –û–ë–©–ï–ú —Ä–µ–∂–∏–º–µ.
    –ö–æ–≥–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤ HomeworkStates/ConversationStates/PromptStates -
    —ç—Ç–æ—Ç –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –í–û–û–ë–©–ï –ù–ï –†–ï–ì–ò–°–¢–†–ò–†–£–ï–¢–°–Ø.
    
    Args:
        message: User message with photo
        state: FSM state
    """
    if not message.photo:
        await message.answer("‚ùå –§–æ—Ç–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        return
    
    logger.info(f"documents.handle_photo: User {message.from_user.id} uploading photo")
    
    # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è
    await state.set_state(DocumentAnalysisStates.processing)
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
    processing_msg = await message.answer(
        "üìá –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Ñ–æ—Ç–æ...\n"
        "–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ (OCR)..."
    )
    
    temp_user_dir = None
    files_to_cleanup: list[Path] = []
    
    try:
        # –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∫–∞—Ç–∞–ª–æ–≥–∞
        temp_base = Path(config.TEMP_DIR)
        temp_base.mkdir(exist_ok=True)
        temp_user_dir = CleanupManager.create_temp_directory(
            temp_base,
            message.from_user.id,
        )
        
        # –û–∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å —Ñ–æ—Ç–æ
        extracted_text = await _extract_text_from_photo(message, temp_user_dir, files_to_cleanup)
        
        if not extracted_text or not extracted_text.strip():
            await message.answer(
                "‚ö†Ô∏è –¢–µ–∫—Å—Ç –≤ —Ñ–æ—Ç–æ –Ω–µ –Ω–∞–π–¥–µ–Ω.\n"
                "–£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ:\n"
                "‚Ä¢ –§–æ—Ç–æ —á–µ—Ç–∫–æ–µ\n"
                "‚Ä¢ –¢–µ–∫—Å—Ç —Ö–æ—Ä–æ—à–æ –≤–∏–¥–µ–Ω\n"
                "‚Ä¢ –ö–æ–Ω—Ç—Ä–∞—Å—Ç–Ω—ã–π —Ñ–æ–Ω"
            )
            await processing_msg.delete()
            await state.clear()
            return
        
        logger.info(f"–û–ß–†: –≠–∫—Å—Ç—Ä–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–æ {len(extracted_text)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        await state.update_data(
            extracted_text=extracted_text,
            original_filename="photo_document",
            user_id=message.from_user.id,
        )
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞
        await processing_msg.edit_text(
            "üìá –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Ñ–æ—Ç–æ...\n"
            f"ü§ñ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å {config.LLM_PROVIDER}..."
        )
        
        # –ê–Ω–∞–ª–∏–∑
        analysis_prompt = (
            "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å –∫–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã.\n"
            "–û–¢–í–ï–¢ –ù–ê –†–£–°–°–ö–û–ú!"
        )
        
        try:
            analysis_result = await llm_factory.analyze_document(
                extracted_text,
                analysis_prompt,
                use_streaming=False,
            )
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –õ–õ–ú: {type(e).__name__}: {str(e)[:100]}")
            await message.answer(
                f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)[:80]}"
            )
            await processing_msg.delete()
            await state.clear()
            return
        
        if not analysis_result:
            await message.answer(
                "‚ùå –ê–Ω–∞–ª–∏–∑ –Ω–µ —É–¥–∞–ª—Å—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞."
            )
            await processing_msg.delete()
            await state.clear()
            return
        
        logger.info(f"–ê–Ω–∞–ª–∏–∑ –æ–∫–æ–Ω—á–µ–Ω ({len(analysis_result)} —Å–∏–º–≤–æ–ª–æ–≤)")
        
        # –û—Ç–≤–µ—Ç
        await processing_msg.delete()
        
        # –û—Ç–ø—Ä–∞–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        splitter = TextSplitter()
        chunks = splitter.split(analysis_result)
        
        for i, chunk in enumerate(chunks, 1):
            prefix = f"*[–ß–∞—Å—Ç—å {i}/{len(chunks)}]*\n\n" if len(chunks) > 1 else ""
            try:
                await message.answer(
                    f"{prefix}{chunk}",
                    parse_mode="Markdown",
                )
            except TelegramNetworkError as e:
                logger.error(f"–û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ: {e}")
                continue
        
        logger.info(
            f"–û—Å–∞–Ω–∞–ª–∏–∑ —Ñ–æ—Ç–æ {message.from_user.id} "
            f"({len(chunks)} —Å–æ–æ–±—â–µ–Ω–∏–π) [{config.LLM_PROVIDER}]"
        )
        await state.clear()
    
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞–±–æ—Ç—ã: {type(e).__name__}: {str(e)[:100]}")
        try:
            await message.answer(
                f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞."
            )
        except:
            pass
        await state.clear()
    
    finally:
        # –û—á–∏—Å—Ç–∫–∞
        if files_to_cleanup:
            await CleanupManager.cleanup_files_async(files_to_cleanup)
        if temp_user_dir and temp_user_dir.exists():
            await CleanupManager.cleanup_directory_async(temp_user_dir)


async def _extract_text_from_photo(
    message: Message,
    temp_dir: Path,
    cleanup_list: list[Path],
) -> str:
    """–û–∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ñ–æ—Ç–æ —á–µ—Ä–µ–∑ OCR.space API.
    
    Args:
        message: Message with photo
        temp_dir: Temporary directory
        cleanup_list: List to add files for cleanup
        
    Returns:
        Extracted text from photo
    """
    try:
        import httpx
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–∞–º–æ–≥–æ –±–æ–ª—å—à–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        photo = message.photo[-1]
        file_info = await message.bot.get_file(photo.file_id)
        
        # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–æ—Ç–æ
        temp_file = temp_dir / f"photo_{photo.file_unique_id}.jpg"
        await message.bot.download_file(file_info.file_path, temp_file)
        cleanup_list.append(temp_file)
        
        # –ù—á—Ç–µ–Ω–∏–µ —Ñ–æ—Ç–æ base64
        with open(temp_file, "rb") as f:
            photo_bytes = f.read()
        
        photo_base64 = base64.b64encode(photo_bytes).decode("utf-8")
        
        # –í—ã–∑–æ–≤ OCR.space API
        async with httpx.AsyncClient() as client:
            response = await asyncio.wait_for(
                client.post(
                    "https://api.ocr.space/parse/image",
                    data={
                        "apikey": config.OCR_SPACE_API_KEY,
                        "base64Image": f"data:image/jpeg;base64,{photo_base64}",
                        "language": "rus",
                        "isOverlayRequired": False,
                        "detectOrientation": True,
                        "scale": True,
                        "OCREngine": 2,
                    },
                ),
                timeout=30.0,
            )
            
            if response.status_code != 200:
                logger.error(f"–û–ß–† –æ—à–∏–±–∫–∞ API: {response.status_code}")
                return ""
            
            result = response.json()
            
            if result.get("IsErroredOnProcessing"):
                error_msg = result.get("ErrorMessage", "Unknown")
                logger.error(f"–û–ß–† –æ—à–∏–±–∫–∞: {error_msg}")
                return ""
            
            # –ï–∫—Å—Ç—Ä–∞–∫—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
            parsed_results = result.get("ParsedResults", [])
            if not parsed_results:
                logger.warning("–û–ß–†: –¢–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return ""
            
            text = parsed_results[0].get("ParsedText", "")
            logger.info(f"–û–ß–†: –í—ã–¥–µ–ª–µ–Ω–æ {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
            return text.strip()
    
    except asyncio.TimeoutError:
        logger.error("–û–ß–†: –¢–∞–π–º–∞—É—Ç API")
        return ""
    except Exception as e:
        logger.error(f"–û–ß–† –æ—à–∏–±–∫–∞: {type(e).__name__}: {str(e)[:100]}")
        return ""
